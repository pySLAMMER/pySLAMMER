name: pySLAMMER Verification

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'tests/verification/**'
      - 'tests/test_verification.py'
      - 'tests/verification_data/**'
      - '.github/workflows/verification.yml'
  pull_request:
    branches: [ main ]
    paths:
      - 'tests/verification/**'
      - 'tests/test_verification.py'
      - 'tests/verification_data/**'
  schedule:
    # Run verification daily at 6 AM UTC
    - cron: '0 6 * * *'
  workflow_dispatch:
    inputs:
      run_slow_tests:
        description: 'Run slow verification tests'
        required: false
        default: 'false'
        type: boolean
      max_tests:
        description: 'Maximum number of tests to run'
        required: false
        default: '50'
        type: string

jobs:
  verification-fast:
    name: Fast Verification Tests
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install uv
      uses: astral-sh/setup-uv@v3
      with:
        version: "latest"
        
    - name: Install dependencies
      run: |
        uv sync --dev
        
    - name: Run fast verification tests
      run: |
        cd tests
        uv run pytest test_verification.py -m "not slow" -v
        
    - name: Run verification framework unit tests
      run: |
        cd tests  
        uv run pytest test_phase2_infrastructure.py -v
        uv run pytest test_phase5_comparisons.py -v
        
    - name: Run small verification sample
      run: |
        cd tests
        PYTHONPATH=/github/workspace/tests uv run python -m verification run --max-tests 10 --output verification_sample.json
        
    - name: Upload verification results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: verification-results-fast
        path: tests/verification_sample.json
        retention-days: 7

  verification-comprehensive:
    name: Comprehensive Verification
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' || github.event.inputs.run_slow_tests == 'true'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install uv
      uses: astral-sh/setup-uv@v3
      with:
        version: "latest"
        
    - name: Install dependencies
      run: |
        uv sync --dev
        
    - name: Run comprehensive verification tests
      run: |
        cd tests
        uv run pytest test_verification.py --runslow -v
        
    - name: Run comprehensive verification
      run: |
        cd tests
        MAX_TESTS=${{ github.event.inputs.max_tests || '100' }}
        PYTHONPATH=/github/workspace/tests uv run python -m verification run --max-tests $MAX_TESTS --output verification_comprehensive.json
        
    - name: Generate verification report
      run: |
        cd tests
        PYTHONPATH=/github/workspace/tests uv run python -m verification report --format text --output verification_report.txt
        PYTHONPATH=/github/workspace/tests uv run python -m verification report --format json --output verification_report.json
        
    - name: Check verification results
      run: |
        cd tests
        # Parse the JSON results to check pass rate
        python3 -c "
        import json
        with open('verification_comprehensive.json', 'r') as f:
            data = json.load(f)
        pass_rate = data['summary']['overall_pass_rate']
        print(f'Overall pass rate: {pass_rate}%')
        if pass_rate < 80.0:
            print('âŒ Verification failed - pass rate below 80%')
            exit(1)
        else:
            print('âœ… Verification passed')
        "
        
    - name: Upload comprehensive results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: verification-results-comprehensive
        path: |
          tests/verification_comprehensive.json
          tests/verification_report.txt
          tests/verification_report.json
        retention-days: 30
        
    - name: Comment PR with results
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          try {
            const report = fs.readFileSync('tests/verification_report.txt', 'utf8');
            const lines = report.split('\n');
            const summary = lines.slice(0, 20).join('\n'); // First 20 lines
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## ðŸ” Verification Results\n\n\`\`\`\n${summary}\n...\n\`\`\`\n\nFull results available in [workflow artifacts](${context.payload.repository.html_url}/actions/runs/${context.runId}).`
            });
          } catch (error) {
            console.log('Could not read verification report:', error);
          }

  verification-matrix:
    name: Multi-Method Verification
    runs-on: ubuntu-latest
    if: github.event_name == 'push' || github.event_name == 'pull_request'
    
    strategy:
      matrix:
        method: [rigid, decoupled, coupled]
        
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install uv
      uses: astral-sh/setup-uv@v3
      with:
        version: "latest"
        
    - name: Install dependencies
      run: |
        uv sync --dev
        
    - name: Run method-specific verification
      run: |
        cd tests
        PYTHONPATH=/github/workspace/tests uv run python -m verification run --methods ${{ matrix.method }} --max-tests 20 --output verification_${{ matrix.method }}.json
        
    - name: Generate method report
      run: |
        cd tests
        PYTHONPATH=/github/workspace/tests uv run python -m verification report --format json --output report_${{ matrix.method }}.json
        
    - name: Upload method results
      uses: actions/upload-artifact@v4
      with:
        name: verification-${{ matrix.method }}
        path: |
          tests/verification_${{ matrix.method }}.json
          tests/report_${{ matrix.method }}.json
        retention-days: 7